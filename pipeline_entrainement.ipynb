{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f69b836",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f07c702",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/15 20:58:05 INFO mlflow.tracking.fluent: Experiment with name 'home_credit_default_risk_Experiment' does not exist. Creating a new experiment.\n"
     ]
    }
   ],
   "source": [
    "# Define experiment name\n",
    "experiment_name = \"home_credit_default_risk_Experiment\"\n",
    "# Set the experiment name\n",
    "mlflow.set_experiment(experiment_name)\n",
    "# Define run name\n",
    "run_name = \"LogisticReg_Run_1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c43b0c5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30750, 724)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset\n",
    "home_credit_default_risk=pd.read_csv('processed_application_train.csv',sep=';')\n",
    "sample_home_credit_default_risk=home_credit_default_risk.sample(n=30750)\n",
    "sample_home_credit_default_risk.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69cf4532",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sample_home_credit_default_risk.drop(['TARGET'], axis=1)\n",
    "y = sample_home_credit_default_risk.TARGET\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73fddbab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\oquach\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\home-credit-default-risk-XEuXw5cG-py3.11\\Lib\\site-packages\\mlflow\\types\\utils.py:435: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "C:\\Users\\oquach\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\home-credit-default-risk-XEuXw5cG-py3.11\\Lib\\site-packages\\mlflow\\types\\utils.py:435: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run ID: 12648b6f7ded4bdc8bda9bae38ad3f99\n",
      "Logged Parameters:\n",
      "Logged Metrics:\n",
      "accuracy: 0.9185365853658537\n",
      "Model Artifact URI: file:///C:/Users/oquach/Documents/OpenClassRoom/home_credit_default_risk/mlruns/548503245526716061/12648b6f7ded4bdc8bda9bae38ad3f99/artifacts\n"
     ]
    }
   ],
   "source": [
    "# Start the MLflow run with a specific run name\n",
    "with mlflow.start_run(run_name=run_name):\n",
    "    # Model training\n",
    "    model = LogisticRegression(max_iter = 6000, solver='saga', random_state=808)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Create input example (sample input data)\n",
    "    input_example = X_train[0:1]\n",
    "    \n",
    "    # Log the model with input example\n",
    "    mlflow.sklearn.log_model(model, \"logisitc_regression_model\", input_example=input_example)\n",
    "    \n",
    "    # Log parameters (optional)\n",
    "    # mlflow.log_param(\"n_estimators\", model.n_estimators)\n",
    "    \n",
    "    # Log metrics (optional)\n",
    "    mlflow.log_metric(\"accuracy\", model.score(X_test, y_test))\n",
    "    \n",
    "    # Print out the current logged details of the MLflow run\n",
    "    run_id = mlflow.active_run().info.run_id\n",
    "    print(f\"Run ID: {run_id}\")\n",
    "    \n",
    "    # Fetch the logged parameters\n",
    "    params = mlflow.get_run(run_id).data.params\n",
    "    print(\"Logged Parameters:\")\n",
    "    for param in params:\n",
    "        print(f\"{param}: {params[param]}\")\n",
    "    \n",
    "    # Fetch the logged metrics\n",
    "    metrics = mlflow.get_run(run_id).data.metrics\n",
    "    print(\"Logged Metrics:\")\n",
    "    for metric in metrics:\n",
    "        print(f\"{metric}: {metrics[metric]}\")\n",
    "    \n",
    "    # Fetch the logged model artifact URI\n",
    "    artifact_uri = mlflow.get_artifact_uri()\n",
    "    print(f\"Model Artifact URI: {artifact_uri}\")\n",
    "    \n",
    "# End the run\n",
    "mlflow.end_run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Poetry Environment",
   "language": "python",
   "name": "poetry-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
